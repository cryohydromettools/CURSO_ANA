{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b88df3d9",
   "metadata": {},
   "source": [
    "# Introducción al Downscaling Climático\n",
    "\n",
    "El **downscaling** o escalamiento climático es una técnica que permite traducir datos de modelos climáticos o reanálisis, de baja resolución espacial, a escalas locales o puntuales, con mayor detalle. Este proceso es esencial para aplicaciones hidrológicas, agrícolas y de gestión de riesgos climáticos.\n",
    "\n",
    "## Métodos comunes de downscaling:\n",
    "\n",
    "1. **Tasa Altitudinal (Lapse Rate Correction)**  \n",
    "   Ajusta las temperaturas simuladas en función de la diferencia de altitud entre el punto de reanálisis y la estación meteorológica, utilizando una tasa estándar (por ejemplo, -6.5 °C/km).  \n",
    "   - Simple, pero útil en regiones montañosas.\n",
    "   - No considera otros factores meteorológicos.\n",
    "\n",
    "2. **Regresión Lineal**  \n",
    "   Utiliza una relación estadística entre variables del reanálisis (predictoras) y datos observados (respuesta), generalmente con una única variable independiente.  \n",
    "   - Método interpretable.\n",
    "   - Supone una relación lineal fija entre variables.\n",
    "\n",
    "3. **XGBoost (Extreme Gradient Boosting)**  \n",
    "   Técnica de **machine learning** basada en árboles de decisión optimizados por gradiente. Permite capturar relaciones no lineales y multivariadas entre datos de reanálisis y observaciones locales.  \n",
    "   - Alto rendimiento predictivo.\n",
    "   - Requiere más datos y calibración cuidadosa.\n",
    "\n",
    "Estas técnicas pueden aplicarse a variables como temperatura, precipitación, viento o radiación, utilizando datos como los del reanálisis **ERA5** y observaciones de estaciones meteorológicas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef6c5dc",
   "metadata": {},
   "source": [
    "## Importar librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81f7455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xarray as xr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import math\n",
    "from scipy.stats import pearsonr\n",
    "# Importa la función de densidad de probabilidad kernel gaussiana de scipy\n",
    "from scipy.stats import gaussian_kde\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9369408e",
   "metadata": {},
   "source": [
    "## Leer datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daa93ba",
   "metadata": {},
   "source": [
    "### Datos ERA5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f46582",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir = '../data/ERA5_AG/'\n",
    "\n",
    "ds1 = xr.open_dataset(f'{path_dir}ERA5_{2016}_ins.nc')\n",
    "ds2 = xr.open_dataset(f'{path_dir}ERA5_{2016}_accum.nc')\n",
    "ds3 = xr.open_dataset(f'{path_dir}ERA5_{2016}_rrr.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a9204f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds3_3h = ds3.resample(valid_time='3h').sum()\n",
    "ds3_3h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3dd6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.merge([ds1, ds2, ds3_3h])\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22896a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.arange(2016, 2019, 1)\n",
    "print(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1b1288",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_list = []\n",
    "for year in years:\n",
    "    ds1 = xr.open_dataset(f'{path_dir}ERA5_{year}_ins.nc')\n",
    "    ds2 = xr.open_dataset(f'{path_dir}ERA5_{year}_accum.nc')\n",
    "    ds3 = xr.open_dataset(f'{path_dir}ERA5_{year}_rrr.nc').resample(valid_time='3h').sum()\n",
    "    ds_list.append(xr.merge([ds1, ds2, ds3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6eba84",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f24a940",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.merge(ds_list)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1342e42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_era5 = ds.isel(latitude=0, longitude=0).to_dataframe().drop(columns=['number', 'latitude', 'longitude', 'expver'])\n",
    "df_era5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed2328d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Velocidad del viento\n",
    "U10 = np.sqrt(df_era5['u10']**2 + df_era5['v10']**2)\n",
    "df_era5['ws2'] = U10 * (np.log(2 / (2.12 * 1000)) / np.log(10 / (2.12 * 1000)))\n",
    "df_era5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e461b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Humedad relativa\n",
    "\n",
    "# Constants for humidity calculation\n",
    "T0 = 273.16\n",
    "a1 = 611.21\n",
    "a3 = 17.502\n",
    "a4 = 32.19\n",
    "R_dry = 287.0597\n",
    "R_vap = 461.5250\n",
    "\n",
    "\n",
    "T_e_sat = a1 * np.exp(a3 * ((df_era5['t2m'] - T0) / (df_era5['t2m'] - a4)))\n",
    "Td_e_sat = a1 * np.exp(a3 * ((df_era5['d2m'] - T0) / (df_era5['d2m'] - a4)))\n",
    "df_era5['rh']  = 100 * Td_e_sat / T_e_sat\n",
    "df_era5['rh'] = df_era5['rh'].clip(lower=0, upper=100)\n",
    "df_era5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c2331c",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 9.81 ## m/s**2\n",
    "df_era5['t2m'] = df_era5['t2m'] - 272.15\n",
    "df_era5['sp'] = df_era5['sp'] / 100\n",
    "df_era5['z'] = df_era5['z'] / g\n",
    "df_era5['ssrd'] = df_era5['ssrd'] / 3600 # J a W\n",
    "df_era5['strd'] = df_era5['strd'] / 3600 # J a W\n",
    "df_era5['tp'] = df_era5['tp'] * 1000 # m a mm\n",
    "df_era5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c47bc9",
   "metadata": {},
   "source": [
    "### Datos AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918fa790",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../data/arteson_2016_2018_1h.csv'\n",
    "df_aws   =  pd.read_csv(filename, sep='\\t')\n",
    "df_aws.TIMESTAMP = pd.to_datetime(df_aws.TIMESTAMP)\n",
    "df_aws.set_index('TIMESTAMP', inplace=True)\n",
    "vars_aws = df_aws.columns\n",
    "\n",
    "df_aws['data_hora_LT'] = df_aws.index.tz_localize('America/Lima')\n",
    "df_aws['data_hora_utc'] = df_aws['data_hora_LT'].dt.tz_convert('UTC')\n",
    "# Remover o timezone (ex: -05:00)\n",
    "df_aws['TIMESTAMP'] = df_aws['data_hora_utc'].dt.tz_localize(None)\n",
    "df_aws.set_index('TIMESTAMP', inplace=True)\n",
    "df_aws = df_aws[vars_aws]\n",
    "df_aws['SWin_Avg'] = df_aws['SWin_Avg'].clip(lower=0, upper=1400)\n",
    "df_aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7d435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dict = {\n",
    "    'SWin_Avg': 'mean',\n",
    "    'Ta_Avg': 'mean',\n",
    "    'Rh_Avg': 'mean',\n",
    "    'WiSp': 'mean',\n",
    "    'pressure': 'mean',\n",
    "    'precip_Tot': 'sum'\n",
    "}\n",
    "\n",
    "df_aws = df_aws.resample('3h').agg(agg_dict)\n",
    "df_aws['pressure'] = df_aws['pressure'] - 172 ## \n",
    "df_aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e91f65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aws.to_csv('../data/aws_AG_3h.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0eb6c8",
   "metadata": {},
   "source": [
    "## Escalamiento ERA5 para AWS T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6034a30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Altura de la estación y del punto ERA5\n",
    "alt_era5 = df_era5['z'].values[0]  # m\n",
    "alt_estacion = 4817  # m\n",
    "lapse_rate = -0.0065  # °C/m\n",
    "\n",
    "print(alt_era5, alt_estacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9e7f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Juntar ambos df\n",
    "df_era5_aws = pd.merge(df_era5, df_aws, left_index=True, right_index=True, how='left')\n",
    "df_era5_aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddd064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_era5_aws.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7145eb7d",
   "metadata": {},
   "source": [
    "### Ecalamiento por Tasa Altitudinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f1fec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_era5_aws['t2m_corr_lp'] = df_era5_aws['t2m'] + lapse_rate * (alt_estacion - alt_era5)\n",
    "df_era5_aws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38347317",
   "metadata": {},
   "source": [
    "### Escalamiento por regresion lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf28c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_era5_aws['ele_aws'] = alt_estacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6908acd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_era5_aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c9bb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 1. Preparación de datos\n",
    "# -------------------------------\n",
    "\n",
    "# Definir las variables que se utilizarán en el análisis:\n",
    "# - 't2m': temperatura del aire a 2 metros (ERA5)\n",
    "# - 'ssrd': radiación solar superficial descendente (ERA5)\n",
    "# - 'u10' y 'v10': componentes zonal y meridional del viento a 10 m (ERA5)\n",
    "# - 'z': altitud del punto ERA5\n",
    "# - 'ele_aws': altitud de la estación meteorológica\n",
    "# - 'Ta_Avg': temperatura media observada en la estación meteorológica\n",
    "#vars = ['t2m', 'ssrd', 'u10', 'v10', 'Ta_Avg']\n",
    "vars = ['t2m', 'ssrd', 'u10', 'v10', 'z', 'ele_aws', 'Ta_Avg']\n",
    "\n",
    "# Crear una copia del DataFrame original que contenga únicamente las variables seleccionadas y eliminar filas con valores nulos\n",
    "df_era5_aws_nonan = df_era5_aws[vars].copy().dropna()\n",
    "\n",
    "# Definir las variables predictoras (features) tomadas de ERA5 y altitud de la estación\n",
    "#X = df_era5_aws_nonan[['t2m', 'ssrd', 'u10', 'v10']]\n",
    "X = df_era5_aws_nonan[['t2m', 'ssrd', 'u10', 'v10', 'z', 'ele_aws']]\n",
    "\n",
    "# Definir la variable objetivo: temperatura promedio observada (de la estación)\n",
    "y = df_era5_aws_nonan['Ta_Avg']\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento (80%) y prueba (20%)\n",
    "# La semilla random_state=42 permite obtener los mismos resultados al ejecutar varias veces\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Imprimir el conjunto de prueba (features) para revisar su contenido\n",
    "print(len(X_train), len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35854bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 2. Modelo de regresión lineal\n",
    "# -------------------------------\n",
    "\n",
    "# Crear una instancia del modelo de regresión lineal de scikit-learn\n",
    "modelo_lr = LinearRegression()\n",
    "\n",
    "# Ajustar (entrenar) el modelo usando los datos de entrenamiento\n",
    "modelo_lr.fit(X_train, y_train)\n",
    "\n",
    "# Usar el modelo entrenado para hacer predicciones sobre los datos de prueba\n",
    "y_pred_lr = modelo_lr.predict(X_test)\n",
    "\n",
    "# Calcular la raíz del error cuadrático medio (RMSE) entre las predicciones y los valores reales\n",
    "rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))\n",
    "\n",
    "# Calcular el coeficiente de determinación R² (explica qué proporción de la varianza se explica por el modelo)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "# Imprimir el RMSE con dos decimales, indicando el error promedio de las predicciones\n",
    "print(f\"[Regresión Lineal] RMSE: {rmse_lr:.2f} °C\")\n",
    "\n",
    "# Imprimir el R² con dos decimales, indicando la calidad del ajuste del modelo\n",
    "print(f\"[Regresión Lineal] R²: {r2_lr:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a067684",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = df_era5_aws[vars].drop(columns=['Ta_Avg'])\n",
    "df_era5_aws['t2m_corr_lineal'] = modelo_lr.predict(X_full)\n",
    "df_era5_aws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302555d5",
   "metadata": {},
   "source": [
    "### Escalamiento con Machine Learing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434ede8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 4. Modelo XGBoost\n",
    "# -------------------------------\n",
    "\n",
    "# Crear un modelo de regresión XGBoost con hiperparámetros definidos:\n",
    "# - n_estimators=100: número de árboles a construir.\n",
    "# - learning_rate=0.1: tasa de aprendizaje que controla la contribución de cada árbol.\n",
    "# - max_depth=4: profundidad máxima de cada árbol (controla la complejidad del modelo).\n",
    "# - random_state=42: semilla aleatoria para reproducibilidad.\n",
    "modelo_xgb = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=4, random_state=42)\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento (X_train, y_train)\n",
    "modelo_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Usar el modelo entrenado para hacer predicciones sobre los datos de prueba\n",
    "y_pred_xgb = modelo_xgb.predict(X_test)\n",
    "\n",
    "# Calcular la raíz del error cuadrático medio (RMSE) entre las predicciones y los datos reales\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "\n",
    "# Calcular el coeficiente de determinación R² (qué tan bien el modelo explica la variabilidad de los datos)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "# Imprimir el RMSE formateado con dos decimales\n",
    "print(f\"[XGBoost] RMSE: {rmse_xgb:.2f} °C\")\n",
    "\n",
    "# Imprimir el R² formateado con dos decimales\n",
    "print(f\"[XGBoost] R²: {r2_xgb:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771daba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = df_era5_aws[vars].drop(columns=['Ta_Avg'])\n",
    "df_era5_aws['t2m_corr_xgb'] = modelo_xgb.predict(X_full)\n",
    "df_era5_aws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35120b4f",
   "metadata": {},
   "source": [
    "## Visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958fd945",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_t2 = ['Ta_Avg', 't2m', 't2m_corr_lp', 't2m_corr_lineal', 't2m_corr_xgb']\n",
    "df_t2 = df_era5_aws[vars_t2]\n",
    "df_t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc582f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_series(df, n_toplot=10**10,):\n",
    "\n",
    "\n",
    "    # Crea una copia del DataFrame original y elimina filas con valores faltantes\n",
    "    df_nan = df.copy().dropna()\n",
    "\n",
    "    # Renombra las columnas a 'OBS' (observado) y 'SIM' (simulado)\n",
    "    df_nan.columns = ['OBS', 'SIM']\n",
    "\n",
    "    # Extrae los valores como arrays numpy\n",
    "    y1 = df_nan['OBS'].values  # serie observada\n",
    "    y2 = df_nan['SIM'].values  # serie simulada\n",
    "\n",
    "    # Crea un arreglo de índices de la misma longitud que las series\n",
    "    idxs = np.arange(len(y1))\n",
    "\n",
    "    # Mezcla aleatoriamente los índices (baraja)\n",
    "    np.random.shuffle(idxs)\n",
    "\n",
    "    # Selecciona hasta 'n_toplot' puntos aleatorios de cada serie\n",
    "    y_expected = y1.reshape(-1)[idxs[:n_toplot]]   # valores observados aleatorios\n",
    "    y_predicted = y2.reshape(-1)[idxs[:n_toplot]]  # valores simulados aleatorios\n",
    "\n",
    "    # Combina ambos arrays en una matriz 2xN para el cálculo de densidad\n",
    "    xy = np.vstack([y_expected, y_predicted])\n",
    "\n",
    "    # Calcula la densidad de puntos usando KDE (kernel density estimation)\n",
    "    z = gaussian_kde(xy)(xy)  # devuelve una densidad para cada punto (x, y)\n",
    "\n",
    "    # Ordena los puntos por densidad ascendente (para que los más densos queden encima al graficar)\n",
    "    idx = z.argsort()\n",
    "\n",
    "    # Reordena los datos según esa densidad\n",
    "    y_plt, ann_plt, z = y_expected[idx], y_predicted[idx], z[idx]\n",
    "\n",
    "    # Devuelve los datos listos para graficar con color basado en densidad\n",
    "    return y_plt, ann_plt, z\n",
    "\n",
    "\n",
    "def get_metrics(df):\n",
    "    # Elimina filas con valores faltantes (NaNs)\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Renombra las columnas a 'OBS' (observado) y 'SIM' (simulado)\n",
    "    df.columns = ['OBS', 'SIM']\n",
    "    \n",
    "    # Calcula el coeficiente de correlación de Pearson entre OBS y SIM\n",
    "    r = pearsonr(df['OBS'], df['SIM'])[0]\n",
    "    \n",
    "    # Calcula el error cuadrático medio (MSE)\n",
    "    MSE = np.square(np.subtract(df['OBS'], df['SIM'])).mean()\n",
    "    \n",
    "    # Calcula el sesgo medio (MBE): diferencia media entre simulado y observado\n",
    "    MBE = np.mean(df['SIM'] - df['OBS']) \n",
    "    \n",
    "    # Calcula la raíz do MSE, o sea, el RMSE\n",
    "    RMSE = math.sqrt(MSE)\n",
    "\n",
    "    # Crea un string con los resultados formateados para mostrar en una figura o tabla\n",
    "    textstr = '\\n'.join((\n",
    "        r'$r=%.2f$' % (r, ),         # Correlación\n",
    "        r'$RMSE=%.3f$' % (RMSE, ),   # RMSE\n",
    "        r'$Bias=%.3f$' % (MBE, ),))   # Sesgo\n",
    "    \n",
    "    # Retorna el texto con las métricas\n",
    "    return textstr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eede08",
   "metadata": {},
   "source": [
    "Este código es útil para generar datos listos para un gráfico de dispersión (scatter) entre dos variables (observada vs simulada), coloreando los puntos según su densidad con KDE. Eso ayuda a visualizar grandes cantidades de datos sin que las zonas densas se oculten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcd0413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de variables simuladas para comparar con observados\n",
    "sim_vars = ['t2m', 't2m_corr_lp', 't2m_corr_lineal', 't2m_corr_xgb']\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "for i, var in enumerate(sim_vars, 1):\n",
    "    # Preparar DataFrame con las columnas observadas y simuladas para la función plot_series y get_metrics\n",
    "    df_plot = df_t2[['Ta_Avg', var]].copy()\n",
    "    \n",
    "    # Obtener datos para graficar con densidad KDE\n",
    "    y_obs, y_sim, dens = plot_series(df_plot)\n",
    "    \n",
    "    # Calcular métricas (r, bias, RMSE)\n",
    "    metrics_text = get_metrics(df_plot)\n",
    "    \n",
    "    # Crear subplot\n",
    "    ax = plt.subplot(2, 2, i)\n",
    "    \n",
    "    # Graficar scatter con color según densidad\n",
    "    sc = ax.scatter(y_obs, y_sim, c=dens, s=15, cmap='viridis')\n",
    "    \n",
    "    # Línea 1:1 para referencia\n",
    "    min_val = min(y_obs.min(), y_sim.min())\n",
    "    max_val = max(y_obs.max(), y_sim.max())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', lw=1)\n",
    "    \n",
    "    # Etiquetas y título\n",
    "    ax.set_xlabel('Temperatura Observada (Ta_Avg) °C')\n",
    "    ax.set_ylabel(f'Temperatura Simulada ({var}) °C')\n",
    "    ax.set_title(f'Comparación Observado vs {var}')\n",
    "    \n",
    "    # Añadir texto con métricas en la esquina superior izquierda\n",
    "    ax.text(0.05, 0.95, metrics_text, transform=ax.transAxes, fontsize=12,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Colorbar para la densidad\n",
    "    plt.colorbar(sc, ax=ax, label='Densidad KDE')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc6839e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de variables simuladas\n",
    "sim_vars = ['t2m', 't2m_corr_lp', 't2m_corr_lineal', 't2m_corr_xgb']\n",
    "\n",
    "# Asegurarse de que el índice es datetime\n",
    "df_t2.index = pd.to_datetime(df_t2.index)\n",
    "\n",
    "# Agrupar por día y calcular la media\n",
    "df_daily = df_t2[['Ta_Avg'] + sim_vars].resample('D').mean().dropna()\n",
    "\n",
    "# Crear figura\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Graficar observaciones\n",
    "plt.plot(df_daily.index, df_daily['Ta_Avg'], label='Observado', color='black', linewidth=1)\n",
    "\n",
    "# Graficar simulaciones\n",
    "for var in sim_vars:\n",
    "    plt.plot(df_daily.index, df_daily[var], label=var, alpha=0.7)\n",
    "\n",
    "# Personalizar gráfico\n",
    "plt.title('Serie Temporal Diaria: Temperatura Observada vs Simulaciones')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Temperatura Media Diaria (°C)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5281b17",
   "metadata": {},
   "source": [
    "## Escalamiento ERA5 para SWin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93598d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 1. Preparación de datos\n",
    "# -------------------------------\n",
    "\n",
    "# Definir las variables que se utilizarán en el análisis:\n",
    "# - 't2m': temperatura del aire a 2 metros (ERA5)\n",
    "# - 'ssrd': radiación solar superficial descendente (ERA5)\n",
    "# - 'rh': humedad relativa (ERA5)\n",
    "# - 'z': altitud del punto ERA5\n",
    "# - 'ele_aws': altitud de la estación meteorológica\n",
    "# - 'SWin_Avg': radiación solar media observada en la estación meteorológica\n",
    "#vars = ['t2m', 'ssrd', 'u10', 'v10', 'Ta_Avg']\n",
    "vars = ['ssrd', 't2m', 'rh', 'z', 'ele_aws', 'SWin_Avg']\n",
    "\n",
    "# Crear una copia del DataFrame original que contenga únicamente las variables seleccionadas y eliminar filas con valores nulos\n",
    "df_era5_aws_nonan = df_era5_aws[vars].copy().dropna()\n",
    "\n",
    "# Definir las variables predictoras (features) tomadas de ERA5 y altitud de la estación\n",
    "#X = df_era5_aws_nonan[['t2m', 'ssrd', 'u10', 'v10']]\n",
    "X = df_era5_aws_nonan[['ssrd', 't2m', 'rh', 'z', 'ele_aws']]\n",
    "\n",
    "# Definir la variable objetivo: temperatura promedio observada (de la estación)\n",
    "y = df_era5_aws_nonan['SWin_Avg']\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento (80%) y prueba (20%)\n",
    "# La semilla random_state=42 permite obtener los mismos resultados al ejecutar varias veces\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Imprimir el conjunto de prueba (features) para revisar su contenido\n",
    "print(len(X_train), len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308806ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41de218",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57437264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 2. Modelo de regresión lineal\n",
    "# -------------------------------\n",
    "\n",
    "# Crear una instancia del modelo de regresión lineal de scikit-learn\n",
    "modelo_lr = LinearRegression()\n",
    "\n",
    "# Ajustar (entrenar) el modelo usando los datos de entrenamiento\n",
    "modelo_lr.fit(X_train, y_train)\n",
    "\n",
    "# Usar el modelo entrenado para hacer predicciones sobre los datos de prueba\n",
    "y_pred_lr = modelo_lr.predict(X_test)\n",
    "\n",
    "# Calcular la raíz del error cuadrático medio (RMSE) entre las predicciones y los valores reales\n",
    "rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))\n",
    "\n",
    "# Calcular el coeficiente de determinación R² (explica qué proporción de la varianza se explica por el modelo)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "# Imprimir el RMSE con dos decimales, indicando el error promedio de las predicciones\n",
    "print(f\"[Regresión Lineal] RMSE: {rmse_lr:.0f} W/m²\")\n",
    "\n",
    "# Imprimir el R² con dos decimales, indicando la calidad del ajuste del modelo\n",
    "print(f\"[Regresión Lineal] R²: {r2_lr:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7168e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = df_era5_aws[vars].drop(columns=['SWin_Avg'])\n",
    "df_era5_aws['SWin_corr_lineal'] = modelo_lr.predict(X_full)\n",
    "df_era5_aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c548346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 4. Modelo XGBoost\n",
    "# -------------------------------\n",
    "\n",
    "# Crear un modelo de regresión XGBoost con hiperparámetros definidos:\n",
    "# - n_estimators=100: número de árboles a construir.\n",
    "# - learning_rate=0.1: tasa de aprendizaje que controla la contribución de cada árbol.\n",
    "# - max_depth=4: profundidad máxima de cada árbol (controla la complejidad del modelo).\n",
    "# - random_state=42: semilla aleatoria para reproducibilidad.\n",
    "modelo_xgb = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=4, random_state=42)\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento (X_train, y_train)\n",
    "modelo_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Usar el modelo entrenado para hacer predicciones sobre los datos de prueba\n",
    "y_pred_xgb = modelo_xgb.predict(X_test)\n",
    "\n",
    "# Calcular la raíz del error cuadrático medio (RMSE) entre las predicciones y los datos reales\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "\n",
    "# Calcular el coeficiente de determinación R² (qué tan bien el modelo explica la variabilidad de los datos)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "# Imprimir el RMSE formateado con dos decimales\n",
    "print(f\"[XGBoost] RMSE: {rmse_xgb:.0f} °W/m²\")\n",
    "\n",
    "# Imprimir el R² formateado con dos decimales\n",
    "print(f\"[XGBoost] R²: {r2_xgb:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ef9d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = df_era5_aws[vars].drop(columns=['SWin_Avg'])\n",
    "df_era5_aws['SWin_corr_xgb'] = modelo_xgb.predict(X_full)\n",
    "df_era5_aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e17d6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_SWin = ['SWin_Avg', 'ssrd', 'SWin_corr_lineal', 'SWin_corr_xgb']\n",
    "df_SWin = df_era5_aws[vars_SWin].resample('1d').mean()\n",
    "df_SWin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c802e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de variables simuladas para comparar con observados\n",
    "sim_vars = ['ssrd', 'SWin_corr_lineal', 'SWin_corr_xgb']\n",
    "\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "for i, var in enumerate(sim_vars, 1):\n",
    "    # Preparar DataFrame con las columnas observadas y simuladas para la función plot_series y get_metrics\n",
    "    df_plot = df_SWin[['SWin_Avg', var]].copy()\n",
    "    \n",
    "    # Obtener datos para graficar con densidad KDE\n",
    "    y_obs, y_sim, dens = plot_series(df_plot)\n",
    "    \n",
    "    # Calcular métricas (r, bias, RMSE)\n",
    "    metrics_text = get_metrics(df_plot)\n",
    "    \n",
    "    # Crear subplot\n",
    "    ax = plt.subplot(1, 3, i)\n",
    "    \n",
    "    # Graficar scatter con color según densidad\n",
    "    sc = ax.scatter(y_obs, y_sim, c=dens, s=15, cmap='viridis')\n",
    "    \n",
    "    # Línea 1:1 para referencia\n",
    "    min_val = min(y_obs.min(), y_sim.min())\n",
    "    max_val = max(y_obs.max(), y_sim.max())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', lw=1)\n",
    "    \n",
    "    # Etiquetas y título\n",
    "    ax.set_xlabel('SWin Observada (SWin_Avg) W/m²')\n",
    "    ax.set_ylabel(f'SWin Simulada ({var}) W/m²')\n",
    "    ax.set_title(f'Comparación Observado vs {var}')\n",
    "    \n",
    "    # Añadir texto con métricas en la esquina superior izquierda\n",
    "    ax.text(0.05, 0.95, metrics_text, transform=ax.transAxes, fontsize=12,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Colorbar para la densidad\n",
    "    plt.colorbar(sc, ax=ax, label='Densidad KDE')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38d5a69",
   "metadata": {},
   "source": [
    "### Escalamiento humedad relativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c408a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 1. Preparación de datos\n",
    "# -------------------------------\n",
    "\n",
    "# Definir las variables que se utilizarán en el análisis:\n",
    "# - 't2m': temperatura del aire a 2 metros (ERA5)\n",
    "# - 'ssrd': radiación solar superficial descendente (ERA5)\n",
    "# - 'rh': humedad relativa (ERA5)\n",
    "# - 'ws2': velocidad del viento (ERA5)\n",
    "# - 'z': altitud del punto ERA5\n",
    "# - 'ele_aws': altitud de la estación meteorológica\n",
    "# - 'Rh_Avg': radiación solar media observada en la estación meteorológica\n",
    "#vars = ['t2m', 'ssrd', 'u10', 'v10', 'Ta_Avg']\n",
    "vars = ['rh', 'ssrd', 't2m', 'ws2', 'z', 'ele_aws', 'Rh_Avg']\n",
    "\n",
    "# Crear una copia del DataFrame original que contenga únicamente las variables seleccionadas y eliminar filas con valores nulos\n",
    "df_era5_aws_nonan = df_era5_aws[vars].copy().dropna()\n",
    "\n",
    "# Definir las variables predictoras (features) tomadas de ERA5 y altitud de la estación\n",
    "#X = df_era5_aws_nonan[['t2m', 'ssrd', 'u10', 'v10']]\n",
    "X = df_era5_aws_nonan[['rh', 'ssrd', 't2m', 'ws2', 'z', 'ele_aws']]\n",
    "\n",
    "# Definir la variable objetivo: temperatura promedio observada (de la estación)\n",
    "y = df_era5_aws_nonan['Rh_Avg']\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento (80%) y prueba (20%)\n",
    "# La semilla random_state=42 permite obtener los mismos resultados al ejecutar varias veces\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Imprimir el conjunto de prueba (features) para revisar su contenido\n",
    "print(len(X_train), len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c68814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 2. Modelo de regresión lineal\n",
    "# -------------------------------\n",
    "\n",
    "# Crear una instancia del modelo de regresión lineal de scikit-learn\n",
    "modelo_lr = LinearRegression()\n",
    "\n",
    "# Ajustar (entrenar) el modelo usando los datos de entrenamiento\n",
    "modelo_lr.fit(X_train, y_train)\n",
    "\n",
    "# Usar el modelo entrenado para hacer predicciones sobre los datos de prueba\n",
    "y_pred_lr = modelo_lr.predict(X_test)\n",
    "\n",
    "# Calcular la raíz del error cuadrático medio (RMSE) entre las predicciones y los valores reales\n",
    "rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))\n",
    "\n",
    "# Calcular el coeficiente de determinación R² (explica qué proporción de la varianza se explica por el modelo)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "# Imprimir el RMSE con dos decimales, indicando el error promedio de las predicciones\n",
    "print(f\"[Regresión Lineal] RMSE: {rmse_lr:.0f} %\")\n",
    "\n",
    "# Imprimir el R² con dos decimales, indicando la calidad del ajuste del modelo\n",
    "print(f\"[Regresión Lineal] R²: {r2_lr:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b50973a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = df_era5_aws[vars].drop(columns=['Rh_Avg'])\n",
    "df_era5_aws['Rh_corr_lineal'] = modelo_lr.predict(X_full)\n",
    "df_era5_aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d14630c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 4. Modelo XGBoost\n",
    "# -------------------------------\n",
    "\n",
    "# Crear un modelo de regresión XGBoost con hiperparámetros definidos:\n",
    "# - n_estimators=100: número de árboles a construir.\n",
    "# - learning_rate=0.1: tasa de aprendizaje que controla la contribución de cada árbol.\n",
    "# - max_depth=4: profundidad máxima de cada árbol (controla la complejidad del modelo).\n",
    "# - random_state=42: semilla aleatoria para reproducibilidad.\n",
    "modelo_xgb = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=4, random_state=42)\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento (X_train, y_train)\n",
    "modelo_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Usar el modelo entrenado para hacer predicciones sobre los datos de prueba\n",
    "y_pred_xgb = modelo_xgb.predict(X_test)\n",
    "\n",
    "# Calcular la raíz del error cuadrático medio (RMSE) entre las predicciones y los datos reales\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "\n",
    "# Calcular el coeficiente de determinación R² (qué tan bien el modelo explica la variabilidad de los datos)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "# Imprimir el RMSE formateado con dos decimales\n",
    "print(f\"[XGBoost] RMSE: {rmse_xgb:.0f} %\")\n",
    "\n",
    "# Imprimir el R² formateado con dos decimales\n",
    "print(f\"[XGBoost] R²: {r2_xgb:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14999e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = df_era5_aws[vars].drop(columns=['Rh_Avg'])\n",
    "df_era5_aws['Rh_corr_xgb'] = modelo_xgb.predict(X_full)\n",
    "df_era5_aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aadba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_rh = ['Rh_Avg', 'rh', 'Rh_corr_lineal', 'Rh_corr_xgb']\n",
    "df_rh = df_era5_aws[vars_rh]#.resample('1d').mean()\n",
    "df_rh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c02f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de variables simuladas para comparar con observados\n",
    "sim_vars = ['rh', 'Rh_corr_lineal', 'Rh_corr_xgb']\n",
    "\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "for i, var in enumerate(sim_vars, 1):\n",
    "    # Preparar DataFrame con las columnas observadas y simuladas para la función plot_series y get_metrics\n",
    "    df_plot = df_rh[['Rh_Avg', var]].copy()\n",
    "    \n",
    "    # Obtener datos para graficar con densidad KDE\n",
    "    y_obs, y_sim, dens = plot_series(df_plot)\n",
    "    \n",
    "    # Calcular métricas (r, bias, RMSE)\n",
    "    metrics_text = get_metrics(df_plot)\n",
    "    \n",
    "    # Crear subplot\n",
    "    ax = plt.subplot(1, 3, i)\n",
    "    \n",
    "    # Graficar scatter con color según densidad\n",
    "    sc = ax.scatter(y_obs, y_sim, c=dens, s=15, cmap='viridis')\n",
    "    \n",
    "    # Línea 1:1 para referencia\n",
    "    min_val = min(y_obs.min(), y_sim.min())\n",
    "    max_val = max(y_obs.max(), y_sim.max())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', lw=1)\n",
    "    \n",
    "    # Etiquetas y título\n",
    "    ax.set_xlabel('RH Observada (Rh_Avg) %²')\n",
    "    ax.set_ylabel(f'RH Simulada ({var}) %')\n",
    "    ax.set_title(f'Comparación Observado vs {var}')\n",
    "    \n",
    "    # Añadir texto con métricas en la esquina superior izquierda\n",
    "    ax.text(0.05, 0.95, metrics_text, transform=ax.transAxes, fontsize=12,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Colorbar para la densidad\n",
    "    plt.colorbar(sc, ax=ax, label='Densidad KDE')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f700c5d4",
   "metadata": {},
   "source": [
    "### Presion del aire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb9d7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 1. Preparación de datos\n",
    "# -------------------------------\n",
    "\n",
    "# Definir las variables que se utilizarán en el análisis:\n",
    "# - 't2m': temperatura del aire a 2 metros (ERA5)\n",
    "# - 'ssrd': radiación solar superficial descendente (ERA5)\n",
    "# - 'rh': humedad relativa (ERA5)\n",
    "# - 'ws2': velocidad del viento (ERA5)\n",
    "# - 'z': altitud del punto ERA5\n",
    "# - 'ele_aws': altitud de la estación meteorológica\n",
    "# - 'Rh_Avg': radiación solar media observada en la estación meteorológica\n",
    "#vars = ['t2m', 'ssrd', 'u10', 'v10', 'Ta_Avg']\n",
    "vars = ['sp', 't2m', 'ssrd', 'z', 'ele_aws', 'pressure']\n",
    "\n",
    "# Crear una copia del DataFrame original que contenga únicamente las variables seleccionadas y eliminar filas con valores nulos\n",
    "df_era5_aws_nonan = df_era5_aws[vars].copy().dropna()\n",
    "\n",
    "# Definir las variables predictoras (features) tomadas de ERA5 y altitud de la estación\n",
    "#X = df_era5_aws_nonan[['t2m', 'ssrd', 'u10', 'v10']]\n",
    "X = df_era5_aws_nonan[['sp', 't2m', 'ssrd', 'z', 'ele_aws']]\n",
    "\n",
    "# Definir la variable objetivo: temperatura promedio observada (de la estación)\n",
    "y = df_era5_aws_nonan['pressure']\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento (80%) y prueba (20%)\n",
    "# La semilla random_state=42 permite obtener los mismos resultados al ejecutar varias veces\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Imprimir el conjunto de prueba (features) para revisar su contenido\n",
    "print(len(X_train), len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb3e77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 2. Modelo de regresión lineal\n",
    "# -------------------------------\n",
    "\n",
    "# Crear una instancia del modelo de regresión lineal de scikit-learn\n",
    "modelo_lr = LinearRegression()\n",
    "\n",
    "# Ajustar (entrenar) el modelo usando los datos de entrenamiento\n",
    "modelo_lr.fit(X_train, y_train)\n",
    "\n",
    "# Usar el modelo entrenado para hacer predicciones sobre los datos de prueba\n",
    "y_pred_lr = modelo_lr.predict(X_test)\n",
    "\n",
    "# Calcular la raíz del error cuadrático medio (RMSE) entre las predicciones y los valores reales\n",
    "rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))\n",
    "\n",
    "# Calcular el coeficiente de determinación R² (explica qué proporción de la varianza se explica por el modelo)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "# Imprimir el RMSE con dos decimales, indicando el error promedio de las predicciones\n",
    "print(f\"[Regresión Lineal] RMSE: {rmse_lr:.2f} hPa\")\n",
    "\n",
    "# Imprimir el R² con dos decimales, indicando la calidad del ajuste del modelo\n",
    "print(f\"[Regresión Lineal] R²: {r2_lr:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9751fad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = df_era5_aws[vars].drop(columns=['pressure'])\n",
    "df_era5_aws['sp_corr_lineal'] = modelo_lr.predict(X_full)\n",
    "df_era5_aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bac0e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 4. Modelo XGBoost\n",
    "# -------------------------------\n",
    "\n",
    "# Crear un modelo de regresión XGBoost con hiperparámetros definidos:\n",
    "# - n_estimators=100: número de árboles a construir.\n",
    "# - learning_rate=0.1: tasa de aprendizaje que controla la contribución de cada árbol.\n",
    "# - max_depth=4: profundidad máxima de cada árbol (controla la complejidad del modelo).\n",
    "# - random_state=42: semilla aleatoria para reproducibilidad.\n",
    "modelo_xgb = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=4, random_state=42)\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento (X_train, y_train)\n",
    "modelo_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Usar el modelo entrenado para hacer predicciones sobre los datos de prueba\n",
    "y_pred_xgb = modelo_xgb.predict(X_test)\n",
    "\n",
    "# Calcular la raíz del error cuadrático medio (RMSE) entre las predicciones y los datos reales\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "\n",
    "# Calcular el coeficiente de determinación R² (qué tan bien el modelo explica la variabilidad de los datos)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "# Imprimir el RMSE formateado con dos decimales\n",
    "print(f\"[XGBoost] RMSE: {rmse_xgb:.2f} hPa\")\n",
    "\n",
    "# Imprimir el R² formateado con dos decimales\n",
    "print(f\"[XGBoost] R²: {r2_xgb:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e07c042",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = df_era5_aws[vars].drop(columns=['pressure'])\n",
    "df_era5_aws['sp_corr_xgb'] = modelo_xgb.predict(X_full)\n",
    "df_era5_aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6ef84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_sp = ['pressure', 'sp', 'sp_corr_lineal', 'sp_corr_xgb']\n",
    "df_sp = df_era5_aws[vars_sp]#.resample('1d').mean()\n",
    "df_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad127941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de variables simuladas para comparar con observados\n",
    "sim_vars = ['sp', 'sp_corr_lineal', 'sp_corr_xgb']\n",
    "\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "for i, var in enumerate(sim_vars, 1):\n",
    "    # Preparar DataFrame con las columnas observadas y simuladas para la función plot_series y get_metrics\n",
    "    df_plot = df_sp[['pressure', var]].copy()\n",
    "    \n",
    "    # Obtener datos para graficar con densidad KDE\n",
    "    y_obs, y_sim, dens = plot_series(df_plot)\n",
    "    \n",
    "    # Calcular métricas (r, bias, RMSE)\n",
    "    metrics_text = get_metrics(df_plot)\n",
    "    \n",
    "    # Crear subplot\n",
    "    ax = plt.subplot(1, 3, i)\n",
    "    \n",
    "    # Graficar scatter con color según densidad\n",
    "    sc = ax.scatter(y_obs, y_sim, c=dens, s=15, cmap='viridis')\n",
    "    \n",
    "    # Línea 1:1 para referencia\n",
    "    min_val = min(y_obs.min(), y_sim.min())\n",
    "    max_val = max(y_obs.max(), y_sim.max())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', lw=1)\n",
    "    \n",
    "    # Etiquetas y título\n",
    "    ax.set_xlabel('SP Observada (Rh_Avg) hPa')\n",
    "    ax.set_ylabel(f'SP Simulada ({var}) hPa')\n",
    "    ax.set_title(f'Comparación Observado vs {var}')\n",
    "    \n",
    "    # Añadir texto con métricas en la esquina superior izquierda\n",
    "    ax.text(0.05, 0.95, metrics_text, transform=ax.transAxes, fontsize=12,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Colorbar para la densidad\n",
    "    plt.colorbar(sc, ax=ax, label='Densidad KDE')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a785d34",
   "metadata": {},
   "source": [
    "### Velocidad del viento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942632c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 1. Preparación de datos\n",
    "# -------------------------------\n",
    "\n",
    "# Definir las variables que se utilizarán en el análisis:\n",
    "# - 't2m': temperatura del aire a 2 metros (ERA5)\n",
    "# - 'ssrd': radiación solar superficial descendente (ERA5)\n",
    "# - 'rh': humedad relativa (ERA5)\n",
    "# - 'ws2': velocidad del viento (ERA5)\n",
    "# - 'z': altitud del punto ERA5\n",
    "# - 'ele_aws': altitud de la estación meteorológica\n",
    "# - 'Rh_Avg': radiación solar media observada en la estación meteorológica\n",
    "#vars = ['t2m', 'ssrd', 'u10', 'v10', 'Ta_Avg']\n",
    "vars = ['ws2', 'u10', 'v10', 't2m', 'ssrd', 'sp', 'z', 'ele_aws', 'WiSp']\n",
    "\n",
    "# Crear una copia del DataFrame original que contenga únicamente las variables seleccionadas y eliminar filas con valores nulos\n",
    "df_era5_aws_nonan = df_era5_aws[vars].copy().dropna()\n",
    "\n",
    "# Definir las variables predictoras (features) tomadas de ERA5 y altitud de la estación\n",
    "#X = df_era5_aws_nonan[['t2m', 'ssrd', 'u10', 'v10']]\n",
    "X = df_era5_aws_nonan[['ws2', 'u10', 'v10', 't2m', 'ssrd', 'sp', 'z', 'ele_aws']]\n",
    "\n",
    "# Definir la variable objetivo: temperatura promedio observada (de la estación)\n",
    "y = df_era5_aws_nonan['WiSp']\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento (80%) y prueba (20%)\n",
    "# La semilla random_state=42 permite obtener los mismos resultados al ejecutar varias veces\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Imprimir el conjunto de prueba (features) para revisar su contenido\n",
    "print(len(X_train), len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d948580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 2. Modelo de regresión lineal\n",
    "# -------------------------------\n",
    "\n",
    "# Crear una instancia del modelo de regresión lineal de scikit-learn\n",
    "modelo_lr = LinearRegression()\n",
    "\n",
    "# Ajustar (entrenar) el modelo usando los datos de entrenamiento\n",
    "modelo_lr.fit(X_train, y_train)\n",
    "\n",
    "# Usar el modelo entrenado para hacer predicciones sobre los datos de prueba\n",
    "y_pred_lr = modelo_lr.predict(X_test)\n",
    "\n",
    "# Calcular la raíz del error cuadrático medio (RMSE) entre las predicciones y los valores reales\n",
    "rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))\n",
    "\n",
    "# Calcular el coeficiente de determinación R² (explica qué proporción de la varianza se explica por el modelo)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "# Imprimir el RMSE con dos decimales, indicando el error promedio de las predicciones\n",
    "print(f\"[Regresión Lineal] RMSE: {rmse_lr:.2f} m/s\")\n",
    "\n",
    "# Imprimir el R² con dos decimales, indicando la calidad del ajuste del modelo\n",
    "print(f\"[Regresión Lineal] R²: {r2_lr:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80efa714",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = df_era5_aws[vars].drop(columns=['WiSp'])\n",
    "df_era5_aws['ws2_corr_lineal'] = modelo_lr.predict(X_full)\n",
    "df_era5_aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43cc3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 4. Modelo XGBoost\n",
    "# -------------------------------\n",
    "\n",
    "# Crear un modelo de regresión XGBoost con hiperparámetros definidos:\n",
    "# - n_estimators=100: número de árboles a construir.\n",
    "# - learning_rate=0.1: tasa de aprendizaje que controla la contribución de cada árbol.\n",
    "# - max_depth=4: profundidad máxima de cada árbol (controla la complejidad del modelo).\n",
    "# - random_state=42: semilla aleatoria para reproducibilidad.\n",
    "modelo_xgb = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=4, random_state=42)\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento (X_train, y_train)\n",
    "modelo_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Usar el modelo entrenado para hacer predicciones sobre los datos de prueba\n",
    "y_pred_xgb = modelo_xgb.predict(X_test)\n",
    "\n",
    "# Calcular la raíz del error cuadrático medio (RMSE) entre las predicciones y los datos reales\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "\n",
    "# Calcular el coeficiente de determinación R² (qué tan bien el modelo explica la variabilidad de los datos)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "# Imprimir el RMSE formateado con dos decimales\n",
    "print(f\"[XGBoost] RMSE: {rmse_xgb:.2f} m/s\")\n",
    "\n",
    "# Imprimir el R² formateado con dos decimales\n",
    "print(f\"[XGBoost] R²: {r2_xgb:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba54fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = df_era5_aws[vars].drop(columns=['WiSp'])\n",
    "df_era5_aws['ws2_corr_xgb'] = modelo_xgb.predict(X_full)\n",
    "df_era5_aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439e6728",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_ws2 = ['WiSp', 'ws2', 'ws2_corr_lineal', 'ws2_corr_xgb']\n",
    "df_ws2 = df_era5_aws[vars_ws2]#.resample('1d').mean()\n",
    "df_ws2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6601f515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de variables simuladas para comparar con observados\n",
    "sim_vars = ['ws2', 'ws2_corr_lineal', 'ws2_corr_xgb']\n",
    "\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "for i, var in enumerate(sim_vars, 1):\n",
    "    # Preparar DataFrame con las columnas observadas y simuladas para la función plot_series y get_metrics\n",
    "    df_plot = df_ws2[['WiSp', var]].copy()\n",
    "    \n",
    "    # Obtener datos para graficar con densidad KDE\n",
    "    y_obs, y_sim, dens = plot_series(df_plot)\n",
    "    \n",
    "    # Calcular métricas (r, bias, RMSE)\n",
    "    metrics_text = get_metrics(df_plot)\n",
    "    \n",
    "    # Crear subplot\n",
    "    ax = plt.subplot(1, 3, i)\n",
    "    \n",
    "    # Graficar scatter con color según densidad\n",
    "    sc = ax.scatter(y_obs, y_sim, c=dens, s=15, cmap='viridis')\n",
    "    \n",
    "    # Línea 1:1 para referencia\n",
    "    min_val = min(y_obs.min(), y_sim.min())\n",
    "    max_val = max(y_obs.max(), y_sim.max())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', lw=1)\n",
    "    \n",
    "    # Etiquetas y título\n",
    "    ax.set_xlabel('WS2 Observada (WiSp) m/s')\n",
    "    ax.set_ylabel(f'WS2 Simulada ({var}) m/s')\n",
    "    ax.set_title(f'Comparación Observado vs {var}')\n",
    "    \n",
    "    # Añadir texto con métricas en la esquina superior izquierda\n",
    "    ax.text(0.05, 0.95, metrics_text, transform=ax.transAxes, fontsize=12,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Colorbar para la densidad\n",
    "    plt.colorbar(sc, ax=ax, label='Densidad KDE')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fa548c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de variables simuladas\n",
    "sim_vars = ['ws2', 'ws2_corr_lineal', 'ws2_corr_xgb']\n",
    "\n",
    "# Asegurarse de que el índice es datetime\n",
    "df_ws2.index = pd.to_datetime(df_ws2.index)\n",
    "\n",
    "# Agrupar por día y calcular la media\n",
    "df_daily = df_ws2[['WiSp'] + sim_vars].resample('D').mean().dropna()\n",
    "\n",
    "# Crear figura\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Graficar observaciones\n",
    "plt.plot(df_daily.index, df_daily['WiSp'], label='Observado', color='black', linewidth=1)\n",
    "\n",
    "# Graficar simulaciones\n",
    "for var in sim_vars:\n",
    "    plt.plot(df_daily.index, df_daily[var], label=var, alpha=0.7)\n",
    "\n",
    "# Personalizar gráfico\n",
    "plt.title('Serie Temporal Diaria: Velocidad del Viento Observada vs Simulaciones')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Velocidad de viento (m/s)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f4f052",
   "metadata": {},
   "source": [
    "#### Correcion incluyendo un analisis climatico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613da6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 1. Preparación de datos\n",
    "# -------------------------------\n",
    "\n",
    "# Definir las variables que se utilizarán en el análisis:\n",
    "# - 't2m': temperatura del aire a 2 metros (ERA5)\n",
    "# - 'ssrd': radiación solar superficial descendente (ERA5)\n",
    "# - 'rh': humedad relativa (ERA5)\n",
    "# - 'ws2': velocidad del viento (ERA5)\n",
    "# - 'z': altitud del punto ERA5\n",
    "# - 'ele_aws': altitud de la estación meteorológica\n",
    "# - 'Rh_Avg': radiación solar media observada en la estación meteorológica\n",
    "#vars = ['t2m', 'ssrd', 'u10', 'v10', 'Ta_Avg']\n",
    "vars = ['ws2', 'u10', 'v10', 't2m', 'ssrd', 'sp', 'z', 'ele_aws', 'WiSp']\n",
    "\n",
    "# Crear una copia del DataFrame original que contenga únicamente las variables seleccionadas y eliminar filas con valores nulos\n",
    "df_era5_aws = df_era5_aws[vars].copy()#.dropna()\n",
    "df_era5_aws\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2755aa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_era5_aws['day_of_year'] = df_era5_aws.index.dayofyear\n",
    "df_era5_aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9b229f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_era5_aws['hour_group'] = (df_era5_aws.index.hour // 3) * 3\n",
    "df_era5_aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffceb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_cols = ['day_of_year', 'hour_group']\n",
    "hourly_clim = df_era5_aws.groupby(clim_cols)['WiSp'].agg(['mean']).rename(columns={'mean':'WiSp_clim'})\n",
    "hourly_clim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73060ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_clim['WiSp_clim'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fa0963",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_era5_aws = df_era5_aws.join(hourly_clim, on=clim_cols)\n",
    "df_era5_aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5181a7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_era5_aws = df_era5_aws.drop(columns=['day_of_year', 'hour_group'])\n",
    "df_era5_aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bb281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_era5_aws_nonan = df_era5_aws.copy().dropna()\n",
    "# Definir las variables predictoras (features) tomadas de ERA5 y altitud de la estación\n",
    "#X = df_era5_aws_nonan[['t2m', 'ssrd', 'u10', 'v10']]\n",
    "X = df_era5_aws_nonan[['ws2', 'WiSp_clim','u10', 'v10', 't2m', 'ssrd', 'sp', 'z', 'ele_aws']]\n",
    "\n",
    "# Definir la variable objetivo: temperatura promedio observada (de la estación)\n",
    "y = df_era5_aws_nonan['WiSp']\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento (80%) y prueba (20%)\n",
    "# La semilla random_state=42 permite obtener los mismos resultados al ejecutar varias veces\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Imprimir el conjunto de prueba (features) para revisar su contenido\n",
    "print(len(X_train), len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f15b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 2. Modelo de regresión lineal\n",
    "# -------------------------------\n",
    "\n",
    "# Crear una instancia del modelo de regresión lineal de scikit-learn\n",
    "modelo_lr = LinearRegression()\n",
    "\n",
    "# Ajustar (entrenar) el modelo usando los datos de entrenamiento\n",
    "modelo_lr.fit(X_train, y_train)\n",
    "\n",
    "# Usar el modelo entrenado para hacer predicciones sobre los datos de prueba\n",
    "y_pred_lr = modelo_lr.predict(X_test)\n",
    "\n",
    "# Calcular la raíz del error cuadrático medio (RMSE) entre las predicciones y los valores reales\n",
    "rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))\n",
    "\n",
    "# Calcular el coeficiente de determinación R² (explica qué proporción de la varianza se explica por el modelo)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "# Imprimir el RMSE con dos decimales, indicando el error promedio de las predicciones\n",
    "print(f\"[Regresión Lineal] RMSE: {rmse_lr:.2f} m/s\")\n",
    "\n",
    "# Imprimir el R² con dos decimales, indicando la calidad del ajuste del modelo\n",
    "print(f\"[Regresión Lineal] R²: {r2_lr:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc906586",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_clim = ['ws2', 'WiSp_clim','u10', 'v10', 't2m', 'ssrd', 'sp', 'z', 'ele_aws']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896cf0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = df_era5_aws[vars_clim]\n",
    "df_era5_aws['ws2_clim_corr_lineal'] = modelo_lr.predict(X_full)\n",
    "df_era5_aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35468969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 4. Modelo XGBoost\n",
    "# -------------------------------\n",
    "\n",
    "# Crear un modelo de regresión XGBoost con hiperparámetros definidos:\n",
    "# - n_estimators=100: número de árboles a construir.\n",
    "# - learning_rate=0.1: tasa de aprendizaje que controla la contribución de cada árbol.\n",
    "# - max_depth=4: profundidad máxima de cada árbol (controla la complejidad del modelo).\n",
    "# - random_state=42: semilla aleatoria para reproducibilidad.\n",
    "modelo_xgb = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=4, random_state=42)\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento (X_train, y_train)\n",
    "modelo_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Usar el modelo entrenado para hacer predicciones sobre los datos de prueba\n",
    "y_pred_xgb = modelo_xgb.predict(X_test)\n",
    "\n",
    "# Calcular la raíz del error cuadrático medio (RMSE) entre las predicciones y los datos reales\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "\n",
    "# Calcular el coeficiente de determinación R² (qué tan bien el modelo explica la variabilidad de los datos)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "# Imprimir el RMSE formateado con dos decimales\n",
    "print(f\"[XGBoost] RMSE: {rmse_xgb:.2f} m/s\")\n",
    "\n",
    "# Imprimir el R² formateado con dos decimales\n",
    "print(f\"[XGBoost] R²: {r2_xgb:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ef2ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = df_era5_aws[vars_clim]\n",
    "df_era5_aws['ws2_clim_corr_xgb'] = modelo_xgb.predict(X_full)\n",
    "df_era5_aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1240d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_ws2 = ['WiSp', 'ws2', 'ws2_clim_corr_lineal', 'ws2_clim_corr_xgb']\n",
    "df_ws2 = df_era5_aws[vars_ws2]#.resample('1d').mean()\n",
    "df_ws2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752d3198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de variables simuladas para comparar con observados\n",
    "sim_vars = ['ws2', 'ws2_clim_corr_lineal', 'ws2_clim_corr_xgb']\n",
    "\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "for i, var in enumerate(sim_vars, 1):\n",
    "    # Preparar DataFrame con las columnas observadas y simuladas para la función plot_series y get_metrics\n",
    "    df_plot = df_ws2[['WiSp', var]].copy()\n",
    "    \n",
    "    # Obtener datos para graficar con densidad KDE\n",
    "    y_obs, y_sim, dens = plot_series(df_plot)\n",
    "    \n",
    "    # Calcular métricas (r, bias, RMSE)\n",
    "    metrics_text = get_metrics(df_plot)\n",
    "    \n",
    "    # Crear subplot\n",
    "    ax = plt.subplot(1, 3, i)\n",
    "    \n",
    "    # Graficar scatter con color según densidad\n",
    "    sc = ax.scatter(y_obs, y_sim, c=dens, s=15, cmap='viridis')\n",
    "    \n",
    "    # Línea 1:1 para referencia\n",
    "    min_val = min(y_obs.min(), y_sim.min())\n",
    "    max_val = max(y_obs.max(), y_sim.max())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', lw=1)\n",
    "    \n",
    "    # Etiquetas y título\n",
    "    ax.set_xlabel('WS2 Observada (WiSp) m/s')\n",
    "    ax.set_ylabel(f'WS2 Simulada ({var}) m/s')\n",
    "    ax.set_title(f'Comparación Observado vs {var}')\n",
    "    \n",
    "    # Añadir texto con métricas en la esquina superior izquierda\n",
    "    ax.text(0.05, 0.95, metrics_text, transform=ax.transAxes, fontsize=12,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Colorbar para la densidad\n",
    "    plt.colorbar(sc, ax=ax, label='Densidad KDE')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e57e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de variables simuladas\n",
    "sim_vars = ['ws2', 'ws2_clim_corr_lineal', 'ws2_clim_corr_xgb']\n",
    "\n",
    "# Asegurarse de que el índice es datetime\n",
    "df_ws2.index = pd.to_datetime(df_ws2.index)\n",
    "\n",
    "# Agrupar por día y calcular la media\n",
    "df_daily = df_ws2[['WiSp'] + sim_vars].resample('D').mean().dropna()\n",
    "\n",
    "# Crear figura\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Graficar observaciones\n",
    "plt.plot(df_daily.index, df_daily['WiSp'], label='Observado', color='black', linewidth=1)\n",
    "\n",
    "# Graficar simulaciones\n",
    "for var in sim_vars:\n",
    "    plt.plot(df_daily.index, df_daily[var], label=var, alpha=0.7)\n",
    "\n",
    "# Personalizar gráfico\n",
    "plt.title('Serie Temporal Diaria: Velocidad del Viento Observada vs Simulaciones')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Velocidad de viento (m/s)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d928bb3b",
   "metadata": {},
   "source": [
    "### Precipitacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d48f833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 1. Preparación de datos\n",
    "# -------------------------------\n",
    "\n",
    "# Definir las variables que se utilizarán en el análisis:\n",
    "# - 't2m': temperatura del aire a 2 metros (ERA5)\n",
    "# - 'ssrd': radiación solar superficial descendente (ERA5)\n",
    "# - 'rh': humedad relativa (ERA5)\n",
    "# - 'ws2': velocidad del viento (ERA5)\n",
    "# - 'z': altitud del punto ERA5\n",
    "# - 'ele_aws': altitud de la estación meteorológica\n",
    "# - 'Rh_Avg': radiación solar media observada en la estación meteorológica\n",
    "#vars = ['t2m', 'ssrd', 'u10', 'v10', 'Ta_Avg']\n",
    "vars = ['tp', 't2m', 'ssrd', 'rh',  'z', 'ele_aws', 'precip_Tot']\n",
    "\n",
    "# Crear una copia del DataFrame original que contenga únicamente las variables seleccionadas y eliminar filas con valores nulos\n",
    "df_era5_aws_nonan = df_era5_aws[vars].copy().dropna()\n",
    "\n",
    "# Definir las variables predictoras (features) tomadas de ERA5 y altitud de la estación\n",
    "#X = df_era5_aws_nonan[['t2m', 'ssrd', 'u10', 'v10']]\n",
    "X = df_era5_aws_nonan[['tp', 't2m', 'ssrd', 'rh',  'z', 'ele_aws']]\n",
    "\n",
    "# Definir la variable objetivo: temperatura promedio observada (de la estación)\n",
    "y = df_era5_aws_nonan['precip_Tot']\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento (80%) y prueba (20%)\n",
    "# La semilla random_state=42 permite obtener los mismos resultados al ejecutar varias veces\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Imprimir el conjunto de prueba (features) para revisar su contenido\n",
    "print(len(X_train), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90ae338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 2. Modelo de regresión lineal\n",
    "# -------------------------------\n",
    "\n",
    "# Crear una instancia del modelo de regresión lineal de scikit-learn\n",
    "modelo_lr = LinearRegression()\n",
    "\n",
    "# Ajustar (entrenar) el modelo usando los datos de entrenamiento\n",
    "modelo_lr.fit(X_train, y_train)\n",
    "\n",
    "# Usar el modelo entrenado para hacer predicciones sobre los datos de prueba\n",
    "y_pred_lr = modelo_lr.predict(X_test)\n",
    "\n",
    "# Calcular la raíz del error cuadrático medio (RMSE) entre las predicciones y los valores reales\n",
    "rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))\n",
    "\n",
    "# Calcular el coeficiente de determinación R² (explica qué proporción de la varianza se explica por el modelo)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "# Imprimir el RMSE con dos decimales, indicando el error promedio de las predicciones\n",
    "print(f\"[Regresión Lineal] RMSE: {rmse_lr:.2f} mm/hr\")\n",
    "\n",
    "# Imprimir el R² con dos decimales, indicando la calidad del ajuste del modelo\n",
    "print(f\"[Regresión Lineal] R²: {r2_lr:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3e6c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = df_era5_aws[vars].drop(columns=['precip_Tot'])\n",
    "df_era5_aws['tp_corr_lineal'] = modelo_lr.predict(X_full)\n",
    "df_era5_aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af5993b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 4. Modelo XGBoost\n",
    "# -------------------------------\n",
    "\n",
    "# Crear un modelo de regresión XGBoost con hiperparámetros definidos:\n",
    "# - n_estimators=100: número de árboles a construir.\n",
    "# - learning_rate=0.1: tasa de aprendizaje que controla la contribución de cada árbol.\n",
    "# - max_depth=4: profundidad máxima de cada árbol (controla la complejidad del modelo).\n",
    "# - random_state=42: semilla aleatoria para reproducibilidad.\n",
    "modelo_xgb = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=4, random_state=42)\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento (X_train, y_train)\n",
    "modelo_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Usar el modelo entrenado para hacer predicciones sobre los datos de prueba\n",
    "y_pred_xgb = modelo_xgb.predict(X_test)\n",
    "\n",
    "# Calcular la raíz del error cuadrático medio (RMSE) entre las predicciones y los datos reales\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "\n",
    "# Calcular el coeficiente de determinación R² (qué tan bien el modelo explica la variabilidad de los datos)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "# Imprimir el RMSE formateado con dos decimales\n",
    "print(f\"[XGBoost] RMSE: {rmse_xgb:.2f} mm\")\n",
    "\n",
    "# Imprimir el R² formateado con dos decimales\n",
    "print(f\"[XGBoost] R²: {r2_xgb:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61e5f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = df_era5_aws[vars].drop(columns=['precip_Tot'])\n",
    "df_era5_aws['tp_corr_xgb'] = modelo_xgb.predict(X_full)\n",
    "df_era5_aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a3ec33",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_tp = ['precip_Tot', 'tp', 'tp_corr_lineal', 'tp_corr_xgb']\n",
    "df_tp = df_era5_aws[vars_tp].resample('1d').mean()\n",
    "df_tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9271f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de variables simuladas para comparar con observados\n",
    "sim_vars = ['tp', 'tp_corr_lineal', 'tp_corr_xgb']\n",
    "\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "for i, var in enumerate(sim_vars, 1):\n",
    "    # Preparar DataFrame con las columnas observadas y simuladas para la función plot_series y get_metrics\n",
    "    df_plot = df_tp[['precip_Tot', var]].copy()\n",
    "    \n",
    "    # Obtener datos para graficar con densidad KDE\n",
    "    y_obs, y_sim, dens = plot_series(df_plot)\n",
    "    \n",
    "    # Calcular métricas (r, bias, RMSE)\n",
    "    metrics_text = get_metrics(df_plot)\n",
    "    \n",
    "    # Crear subplot\n",
    "    ax = plt.subplot(1, 3, i)\n",
    "    \n",
    "    # Graficar scatter con color según densidad\n",
    "    sc = ax.scatter(y_obs, y_sim, c=dens, s=15, cmap='viridis')\n",
    "    \n",
    "    # Línea 1:1 para referencia\n",
    "    min_val = min(y_obs.min(), y_sim.min())\n",
    "    max_val = max(y_obs.max(), y_sim.max())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', lw=1)\n",
    "    \n",
    "    # Etiquetas y título\n",
    "    ax.set_xlabel('TP Observada (precip_Tot) mm')\n",
    "    ax.set_ylabel(f'TP Simulada ({var}) mm')\n",
    "    ax.set_title(f'Comparación Observado vs {var}')\n",
    "    \n",
    "    # Añadir texto con métricas en la esquina superior izquierda\n",
    "    ax.text(0.05, 0.95, metrics_text, transform=ax.transAxes, fontsize=12,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Colorbar para la densidad\n",
    "    plt.colorbar(sc, ax=ax, label='Densidad KDE')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453ee987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de variables simuladas\n",
    "sim_vars = ['tp', 'tp_corr_lineal', 'tp_corr_xgb']\n",
    "\n",
    "# Asegurarse de que el índice es datetime\n",
    "df_ws2.index = pd.to_datetime(df_ws2.index)\n",
    "\n",
    "# Agrupar por día y calcular la media\n",
    "df_daily = df_tp[['precip_Tot'] + sim_vars].resample('D').mean().dropna()\n",
    "\n",
    "# Crear figura\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Graficar observaciones\n",
    "plt.plot(df_daily.index, df_daily['precip_Tot'], label='Observado', color='black', linewidth=1)\n",
    "\n",
    "# Graficar simulaciones\n",
    "for var in sim_vars:\n",
    "    plt.plot(df_daily.index, df_daily[var], label=var, alpha=0.7)\n",
    "\n",
    "# Personalizar gráfico\n",
    "plt.title('Serie Temporal Diaria: Precipitacion Observada vs Simulaciones')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Precipitacion (mm)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MassBalanceMachine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
